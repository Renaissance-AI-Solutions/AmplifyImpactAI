import logging
import random
from typing import List, Dict, Optional, Any
from datetime import datetime, timezone
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from flask_login import current_user
from flask import current_app
from app import db
from app.models import KnowledgeDocument, KnowledgeChunk, ScheduledPost
from app.services.knowledge_base_manager import KnowledgeBaseManager
from app.services.content_generator import ContentGenerator, GenerationConfig

logger = logging.getLogger(__name__)

class PostGeneratorService:
    def __init__(self):
        self.llm_service = ContentGenerator()
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words='english',
            ngram_range=(1, 2)
        )
        # Platform-specific character limits
        self.platform_limits = {
            'twitter': 280,
            'linkedin': 3000,
            'facebook': 2000,
            'instagram': 2200
        }
        print("--- DEBUG: PostGeneratorService initialized (without immediate KBManager) ---")

    def _get_kb_manager(self):
        """Helper to get a KB manager instance for the current authenticated user."""
        if current_user and hasattr(current_user, 'is_authenticated') and current_user.is_authenticated:
            if hasattr(current_user, 'id'):
                return KnowledgeBaseManager(portal_user_id=current_user.id)
            else:
                logger.error("Current user is authenticated but has no 'id' attribute.")
                return None
        logger.warning("_get_kb_manager called when no authenticated user is available.")
        return None
        
    def extract_topics(self, document_id: int, num_topics: int = 5) -> List[Dict]:
        """Extract main topics from a document using TF-IDF and clustering."""
        try:
            # Get document chunks
            chunks = db.session.scalars(
                db.select(KnowledgeChunk)
                .filter_by(document_id=document_id)
            ).all()
            
            if not chunks:
                logger.warning(f"No chunks found for document {document_id}")
                return []
                
            # Extract text from chunks
            chunk_texts = [chunk.chunk_text for chunk in chunks]
            
            # Create TF-IDF matrix
            tfidf_matrix = self.vectorizer.fit_transform(chunk_texts)
            
            # Perform clustering to group similar topics
            kmeans = KMeans(n_clusters=min(num_topics, len(chunk_texts)))
            kmeans.fit(tfidf_matrix)
            
            # Get top terms for each cluster
            order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]
            terms = self.vectorizer.get_feature_names_out()
            
            # Extract topics
            topics = []
            for i in range(min(num_topics, len(chunk_texts))):
                top_terms = [terms[ind] for ind in order_centroids[i, :5]]
                relevant_chunks = [
                    chunks[j] for j, label in enumerate(kmeans.labels_)
                    if label == i
                ]
                topics.append({
                    'terms': top_terms,
                    'chunks': relevant_chunks,
                    'score': np.mean([
                        tfidf_matrix[j].max()
                        for j, label in enumerate(kmeans.labels_)
                        if label == i
                    ])
                })
            
            # Sort topics by score
            topics.sort(key=lambda x: x['score'], reverse=True)
            return topics
            
        except Exception as e:
            logger.error(f"Error extracting topics from document {document_id}: {e}")
            return []
            
    def generate_post_content(self, topic: Dict, template_type: str = 'informational') -> str:
        """Generate post content based on topic and template type."""
        templates = {
            'informational': [
                "Did you know? {key_point}",
                "Here's an interesting fact: {key_point}",
                "Learn something new: {key_point}"
            ],
            'promotional': [
                "Discover how {key_point}",
                "Want to learn more about {topic}? {key_point}",
                "Explore the world of {topic} - {key_point}"
            ],
            'educational': [
                "Understanding {topic}: {key_point}",
                "Let's dive into {topic}: {key_point}",
                "Key insight about {topic}: {key_point}"
            ],
            'engagement': [
                "What do you think about {key_point}?",
                "Share your thoughts: {key_point}",
                "Have you experienced this? {key_point}"
            ]
        }
        
        try:
            # Get template options for the specified type
            template_options = templates.get(template_type, templates['informational'])
            
            # Select a template randomly
            template = random.choice(template_options)
            
            # Get the most relevant chunk
            chunk = topic['chunks'][0] if topic['chunks'] else None
            if not chunk:
                return ""
                
            # Extract key information
            topic_terms = ' '.join(topic['terms'][:2])
            key_point = chunk.chunk_text[:200] + "..." if len(chunk.chunk_text) > 200 else chunk.chunk_text
            
            # Format the post
            post_content = template.format(
                topic=topic_terms,
                key_point=key_point
            )
            
            return post_content
            
        except Exception as e:
            logger.error(f"Error generating post content: {e}")
            return ""
            
    def generate_content(
        self, document_id: int, platform: str = 'twitter',
        tone: str = 'informative', style: str = 'concise', topic: Optional[str] = None, max_length: int = 280,
        include_hashtags: bool = True, include_emoji: bool = True, use_llm: bool = True, portal_user_id: Optional[int] = None
    ) -> str:
        """Generate content optimized for a specific platform with enhanced customization.
        
        Args:
            document_id: ID of the knowledge document to use
            platform: Target platform (twitter, linkedin, facebook, instagram)
            tone: Content tone (informative, friendly, formal, urgent, inspirational, humorous)
            style: Content style (concise, detailed, question, story)
            topic: Optional specific topic to focus on
            max_length: Maximum length for the content
            include_hashtags: Whether to include hashtags
            include_emoji: Whether to include emoji
            use_llm: Whether to use LLM for content generation (if False, falls back to template)
            portal_user_id: User ID for API key retrieval
            
        Returns:
            Generated content as string
        """
        try:
            # Extract topics from the document
            topics = self.extract_topics(document_id)
            if not topics:
                logger.warning(f"No topics found for document {document_id}")
                return ""
                
            # Select a relevant topic
            if topic:
                # If a specific topic is requested, find the most relevant one
                topic_scores = []
                for t in topics:
                    # Calculate similarity between requested topic and available topics
                    terms = set(t['terms'])
                    requested_terms = set(topic.lower().split())
                    overlap = len(terms.intersection(requested_terms))
                    topic_scores.append((t, overlap))
                    
                # Sort by overlap score
                topic_scores.sort(key=lambda x: x[1], reverse=True)
                selected_topic = topic_scores[0][0] if topic_scores else topics[0]
            else:
                # Otherwise use the highest-scoring topic
                selected_topic = topics[0]
            
            # If LLM is requested and available, use it for content generation
            if use_llm and self.llm_service:
                try:
                    # Get document information
                    document = db.session.get(KnowledgeDocument, document_id)
                    doc_filename = document.filename if document else "Unknown document"
                    
                    # Extract key points from chunks
                    key_points = []
                    for chunk in selected_topic['chunks'][:3]:  # Use top 3 chunks
                        # Limit chunk text to reasonable size
                        chunk_text = chunk.chunk_text[:250] + "..." if len(chunk.chunk_text) > 250 else chunk.chunk_text
                        key_points.append(chunk_text)
                    
                    # Create hashtags from key terms
                    hashtags = [term.replace(' ', '') for term in selected_topic['terms'][:5]]
                    
                    # Prepare content context for LLM
                    content_context = {
                        "topic": topic or ' '.join(selected_topic['terms'][:3]),
                        "key_points": key_points,
                        "platform": platform,
                        "tone": tone,
                        "style": style,
                        "max_length": max_length,
                        "hashtags": hashtags if include_hashtags else [],
                        "call_to_action": "Learn more on our website" if style != "question" else "Share your thoughts!"
                    }
                    
                    # Call the LLM service
                    llm_content = self.llm_service.generate_content(
                        content_context=content_context,
                        portal_user_id=portal_user_id or (current_user.id if hasattr(current_user, 'id') else None)
                    )
                    
                    logger.info(f"Generated content using LLM for document {document_id}")
                    return llm_content
                    
                except Exception as llm_error:
                    logger.warning(f"LLM generation failed, falling back to template: {llm_error}")
                    # Fall back to template-based generation
            
            # Template-based generation (fallback if LLM fails or not requested)
            # Extract information from the topic
            key_terms = selected_topic['terms']
            chunks = selected_topic['chunks']
            
            # Select a template based on tone and style
            templates = {
                'informational': [
                    "Did you know? {key_point}",
                    "Here's an interesting fact about {topic}: {key_point}",
                    "Learn more about {topic}: {key_point}"
                ],
                'promotional': [
                    "Discover how {topic} can transform your approach! {key_point}",
                    "Want to improve your understanding of {topic}? {key_point}",
                    "Take your knowledge of {topic} to the next level. {key_point}"
                ],
                'educational': [
                    "Understanding {topic}: {key_point}",
                    "The essentials of {topic}: {key_point}",
                    "A key insight about {topic}: {key_point}"
                ],
                'engagement': [
                    "What do you think about this? {key_point} #LetUsKnow",
                    "Have you experienced this? {key_point} Share your thoughts!",
                    "We'd love your perspective on {topic}: {key_point}"
                ]
            }
            
            # Adjust content based on style
            if style == 'question':
                templates = {
                    'informational': [
                        "Did you know about {topic}? {key_point}",
                        "Have you heard that {key_point}?",
                        "Are you aware of how {topic} affects us? {key_point}"
                    ],
                    'promotional': [
                        "Want to discover how {topic} can help? {key_point}",
                        "Ready to transform your approach to {topic}? {key_point}",
                        "Looking for better results with {topic}? {key_point}"
                    ],
                    'educational': [
                        "Curious about {topic}? {key_point}",
                        "Want to understand {topic} better? {key_point}",
                        "How much do you know about {topic}? {key_point}"
                    ],
                    'engagement': [
                        "What's your experience with {topic}? {key_point}",
                        "How would you handle this? {key_point}",
                        "Do you agree that {key_point}? Why or why not?"
                    ]
                }
            elif style == 'story':
                templates = {
                    'informational': [
                        "I recently learned about {topic} and was surprised to discover that {key_point}",
                        "While researching {topic}, we uncovered something interesting: {key_point}",
                        "The story of {topic} reveals an important truth: {key_point}"
                    ],
                    'promotional': [
                        "A client's journey with {topic} led to amazing results: {key_point}",
                        "We've been exploring {topic} and discovered that {key_point}",
                        "Our team's experience with {topic} taught us that {key_point}"
                    ],
                    'educational': [
                        "The evolution of {topic} teaches us that {key_point}",
                        "History shows us something fascinating about {topic}: {key_point}",
                        "When you study {topic}, you'll find that {key_point}"
                    ],
                    'engagement': [
                        "Here's a story that might resonate: {key_point} What's yours?",
                        "We've witnessed this happen with {topic}: {key_point} Have you?",
                        "Someone recently told us about their experience with {topic}: {key_point} Share yours!"
                    ]
                }
            
            # Select tone type (default to informational if not found)
            template_options = templates.get(tone, templates['informational'])
            
            # Select a template randomly
            template = random.choice(template_options)
            
            # Get the most relevant chunk
            chunk = chunks[0] if chunks else None
            if not chunk:
                return ""
                
            # Extract key information
            topic_terms = ' '.join(key_terms[:2])
            key_point = chunk.chunk_text[:200] + "..." if len(chunk.chunk_text) > 200 else chunk.chunk_text
            
            # Format content
            content = template.format(topic=topic_terms, key_point=key_point)
            
            # Add hashtags if requested
            if include_hashtags:
                # Create hashtags from key terms
                hashtags = [f"#{term.replace(' ', '')}" for term in key_terms[:2]]
                platform_tag = f"#{platform.capitalize()}" if platform in ['twitter', 'linkedin', 'facebook', 'instagram'] else ""
                
                # Add hashtags based on platform limit
                if platform == 'twitter' and len(content) + len(' '.join(hashtags)) + 1 <= max_length:
                    content += "\n" + ' '.join(hashtags)
                elif platform in ['linkedin', 'facebook', 'instagram'] and len(content) + len(' '.join(hashtags + [platform_tag])) + 1 <= max_length:
                    content += "\n" + ' '.join(hashtags + ([platform_tag] if platform_tag else []))
            
            # Add emoji if requested
            if include_emoji:
                # Map topics to relevant emoji
                topic_first_term = selected_topic['terms'][0].lower() if selected_topic['terms'] else ""
                emoji_map = {
                    'business': 'ðŸ’¼',
                    'money': 'ðŸ’°',
                    'growth': 'ðŸ“ˆ',
                    'success': 'ðŸ†',
                    'technology': 'ðŸ’»',
                    'innovation': 'ðŸ’¡',
                    'health': 'ðŸ©º',
                    'education': 'ðŸ“š',
                    'research': 'ðŸ”¬',
                    'data': 'ðŸ“Š',
                    'marketing': 'ðŸ“±',
                    'social': 'ðŸ¤',
                    'environment': 'ðŸŒ¿',
                    'climate': 'ðŸŒ',
                    'finance': 'ðŸ’µ',
                    'investment': 'ðŸ“‹',
                    'leadership': 'ðŸ‘‘',
                    'development': 'ðŸ› ï¸',
                    'strategy': 'ðŸŽ¯',
                    'planning': 'ðŸ“'
                }
                
                # Find matching emoji or use default
                emoji = None
                for key, value in emoji_map.items():
                    if key in topic_first_term:
                        emoji = value
                        break
                        
                if not emoji:
                    # Default emoji based on tone
                    tone_emoji = {
                        'informative': 'ðŸ“Œ',
                        'friendly': 'ðŸ˜Š',
                        'formal': 'ðŸ“¢',
                        'urgent': 'âš¡',
                        'inspirational': 'âœ¨',
                        'humorous': 'ðŸ˜„'
                    }
                    emoji = tone_emoji.get(tone, 'ðŸ“Œ')
                    
                # Add emoji to beginning if it fits
                if len(content) + 2 <= max_length:
                    content = f"{emoji} {content}"
                    
            # Ensure content is within max_length
            if len(content) > max_length:
                content = content[:max_length-3] + "..."
                
            return content
            
        except Exception as e:
            logger.error(f"Error in generate_content: {e}", exc_info=True)
            return ""
            
    def create_scheduled_post(
        self,
        portal_user_id: int,
        managed_account_id: int,
        document_id: int,
        template_type: str = 'informational',
        scheduled_time: Optional[datetime] = None
    ) -> Optional[ScheduledPost]:
        """Create a scheduled post from document content."""
        try:
            # Use the KB manager for the current user if needed (example usage)
            kb_manager = self._get_kb_manager()
            # If you want to use kb_manager, you can call methods on it here
            # For now, we'll continue using extract_topics as before

            topics = self.extract_topics(document_id)
            if not topics:
                logger.warning(f"No topics found for document {document_id}")
                return None
                
            # Generate post content from the highest-scoring topic
            content = self.generate_post_content(topics[0], template_type)
            if not content:
                logger.warning("Failed to generate post content")
                return None
                
            # Create scheduled post
            post = ScheduledPost(
                portal_user_id=portal_user_id,
                managed_account_id=managed_account_id,
                content=content,
                scheduled_time=scheduled_time or datetime.now(timezone.utc),
                status="pending"
            )
            
            db.session.add(post)
            db.session.commit()
            
            logger.info(f"Created scheduled post {post.id} from document {document_id}")
            return post
            
        except Exception as e:
            logger.error(f"Error creating scheduled post: {e}")
            return None
